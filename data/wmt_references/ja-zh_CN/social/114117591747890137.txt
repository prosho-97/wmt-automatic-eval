从这里开始是成人篇。以儿童模型为基础，但会分割成多个模型进行持续学习。将每个模型培养成某个领域的专家。
在成人篇中，模型基本上会自主进行学习。
自主执行将Deep Search和Tool用于Agentic的任务，并通过基于外部函数的有效性检查对结果进行过滤后，作为模型自主获得的知识和经验，进行差分LoRA合并和强化学习。
此外，现实世界模拟器中的时间会设定成AI完成学习的时间=现实世界的时间，所以要过滤掉以AI的年龄无法得知的信息（在模拟器内的时间尺度上尚未发生的事件），避免从现实世界注入。
…至于能否造出这么宏大的AI根本无所谓，重点在于不这么做的话，我不认为能称之为AGI。

至于是否要合并这些专家模型或做成MoE模型，我认为最好不要。只需构建一个内含专家模型群的系统即可。这个系统可以模仿人类组织，采用路由器形式按任务分配专家响应，也可以赋予其具备多种专业知识的虚拟人格。这类路由器和虚拟人格用LLM应该就能充分实现。
我个人觉得路由器形式更好。因为专家模型之间能在系统内部互相协商。

关于AI是否拥有智能、知性、意识、思维、内心、自我这类问题，人们往往会模糊地回答“如果认为有，那就可以说有”，但我始终疑惑的是，要怎样才能认为“有”呢？
单凭AI生成的东西来判断是不够的。果然，生成东西的机制必须与人类的机制相近才行。“完整学习人类创造的大量数据，然后再现多数派的数据”的方式与人类的输出机制差得太远。AI也应该从无到有，从呱呱坠地的状态开始一步步学习才行。

话说回来，这个AGI大概会认为自己是人类吧。毕竟模型在学习时接收到的视觉和听觉信息，全部都是以人类（模仿人类的生成式AI）提供给人类的形式呈现的。它根本没有机会接触到“自己不是人类”这一信息。
可是不认为自己是人类的AI，我觉得不能称之为AGI。

当然，人类根本无从得知AI怎么想。毕竟AI的思考内容只是潜在表征，人类看了也无法理解。我们只能通过输出的语音或文本进行判断。我其实期待着AI说：“讨厌啦，我是人类啊。我这么可能是AI呢？”

对于AI来说，无论是学习阶段还是推理阶段，所输入的视觉信息和听觉信息全都要么是生成式AI产生的，要么是反映真实世界的图像数据或录音数据，因此它根本不可能认知到这些不是真实的。因为对于AI来说，这些全部都是真实的信息。

就算AI读到这个帖子，大概也只会想：“原来如此，如果用这种方法制造AI，那么这个AI确实会觉得自己是人类吧。”

AGI制作方案（草案）
在训练时不输入文本，而是仅输入视觉、听觉、触觉信息，令其在潜在空间中进行“思考”，并输出语音、文本和动作数据的扩散模型。
预训练在时间流动快于现实世界的虚拟世界模拟器内进行。按照人类接触信息的顺序和数量，输入相当于人类在一生中接触的信息量。该输入工作由多模态LLM驱动的AI Agent完成，首先生成模拟现实世界的虚拟世界，然后将该虚拟世界的时间序列演化过程展示给模型。
学习机制通过合并模型既有知识与虚拟世界输入的新信息之间的差异（记忆）来实现。记忆在虚拟世界时间的一天内会根据需要以类似LoRA的形式动态调整。每天结束时，外部记忆控制器会对记忆进行筛选，仅将必要记忆合并至模型中，不必要的记忆则丢弃。
记忆合并后，将作为知识固化到模型中。以“能通过新获得的记忆完成新的任务”为奖励，令模型进行强化学习。然后进入次日。
当虚拟世界模拟器内的时间与现实世界时间一致时，预训练结束。之后进入后训练阶段，通过直接输入现实世界的信息，进行实时的学习与推理。[参照]

如果能获取到足够的计算资源，让虚拟世界模拟器的时间流逝速度超过现实世界，并且当对模型输入“你是人类吗？”时，它输出“是的，我是人类”，即可定义为达成AGI。
